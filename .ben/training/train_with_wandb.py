#!/usr/bin/env python3
"""
Two-Tower Training with Weights & Biases Integration

This script extends the standard training to include W&B logging and hyperparameter sweeps.
It's designed to work with wandb sweep for automated hyperparameter tuning.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import pickle
import os
from tqdm import tqdm
import argparse
from typing import Dict, List, Optional
import json
from datetime import datetime
import sys

# Weights & Biases
import wandb

# Import training components
from train_two_tower_from_triplets import PreprocessedMSMarcoDataset, train_from_triplets
from two_tower_model import TwoTowerModel, ContrastiveLoss, MarginContrastiveLoss, TripletLoss, TwoTowerCollator

# Evaluation module will be imported dynamically based on config
EVALUATION_AVAILABLE = False
evaluate_trained_model = None

def setup_evaluation_module(evaluation_path: str = "./evaluation") -> bool:
    """
    Dynamically import the evaluation module from the specified path.
    
    Args:
        evaluation_path: Path to the evaluation directory
        
    Returns:
        True if evaluation module was successfully imported, False otherwise
    """
    global EVALUATION_AVAILABLE, evaluate_trained_model
    
    try:
        # Add evaluation path to sys.path if not already there
        abs_eval_path = os.path.abspath(evaluation_path)
        if abs_eval_path not in sys.path:
            sys.path.insert(0, abs_eval_path)
        
        # Import the evaluation function
        from eval_integration import evaluate_trained_model as eval_func
        evaluate_trained_model = eval_func
        EVALUATION_AVAILABLE = True
        
        print(f"‚úÖ Evaluation module loaded from: {evaluation_path}")
        return True
        
    except ImportError as e:
        print(f"‚ö†Ô∏è  Warning: Evaluation module not found at {evaluation_path}. Using fallback evaluation.")
        print(f"   Import error: {e}")
        EVALUATION_AVAILABLE = False
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: Error loading evaluation module from {evaluation_path}: {e}")
        EVALUATION_AVAILABLE = False
        return False
    
def simple_evaluation(model, device, triplets_file, max_queries=100):
    """
    Simple evaluation using training triplets data.
    This gives a rough estimate of training progress.
    """
    try:
        # Load some triplets for evaluation
        with open(triplets_file, 'rb') as f:
            data = pickle.load(f)
        
        # Extract triplets from the data structure
        if isinstance(data, dict) and 'triplets' in data:
            triplets_data = data['triplets']
        elif isinstance(data, list):
            triplets_data = data
        else:
            raise ValueError(f"Unexpected data structure: {type(data)}")
        
        # Use a subset for evaluation
        eval_triplets = triplets_data[:min(max_queries, len(triplets_data))]
        
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for triplet in eval_triplets:
                query_text = triplet['query_text']
                pos_doc_text = triplet['pos_passage_text']
                neg_doc_text = triplet['neg_passage_text']
                
                # Tokenize
                query_ids = model.tokenize(query_text).unsqueeze(0).to(device)
                pos_doc_ids = model.tokenize(pos_doc_text).unsqueeze(0).to(device)
                neg_doc_ids = model.tokenize(neg_doc_text).unsqueeze(0).to(device)
                
                # Get embeddings
                query_emb = model.encode_query(query_ids)
                pos_doc_emb = model.encode_document(pos_doc_ids)
                neg_doc_emb = model.encode_document(neg_doc_ids)
                
                # Compute similarities
                pos_sim = torch.cosine_similarity(query_emb, pos_doc_emb, dim=1)
                neg_sim = torch.cosine_similarity(query_emb, neg_doc_emb, dim=1)
                
                # Check if positive similarity is higher
                if pos_sim.item() > neg_sim.item():
                    correct += 1
                total += 1
        
        accuracy = correct / total if total > 0 else 0.0
        
        # Return mock metrics with the accuracy as a baseline
        return {
            "MRR": accuracy * 0.5,  # Rough approximation
            "MRR@10": accuracy * 0.5,
            "Recall@10": accuracy,
            "NDCG@10": accuracy * 0.6,
            "MAP": accuracy * 0.4,
            "triplet_accuracy": accuracy,
            "evaluation_type": "simple_triplet_eval"
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Simple evaluation failed: {e}")
        return {"MRR": 0.0, "MRR@10": 0.0, "Recall@10": 0.0, "NDCG@10": 0.0, "MAP": 0.0}

def evaluate_trained_model_wrapper(model, device, epoch, data_path, max_queries):
    """Wrapper that tries full evaluation first, then falls back to simple evaluation."""
    if EVALUATION_AVAILABLE:
        try:
            return evaluate_trained_model(model, device, epoch, data_path, max_queries)
        except Exception as e:
            print(f"‚ö†Ô∏è  Full evaluation failed: {e}")
            print("üîÑ Falling back to simple evaluation...")
    
    # Fallback: use simple evaluation with training data
    # Try to find the triplets file
    possible_triplets = [
        "../data/msmarco_triplets_2k_20250618_171140.pkl",
        "../data/msmarco_triplets_5k_20250618_171329.pkl",
        "../data/msmarco_triplets_88k_20250617_112750.pkl",
        "./data/msmarco_triplets_2k_20250618_171140.pkl",
        "./data/msmarco_triplets_5k_20250618_171329.pkl",
        "./data/msmarco_triplets_88k_20250617_112750.pkl"
    ]
    
    for triplets_file in possible_triplets:
        if os.path.exists(triplets_file):
            print(f"üìä Using simple evaluation with: {os.path.basename(triplets_file)}")
            return simple_evaluation(model, device, triplets_file, max_queries)
    
    print("‚ö†Ô∏è  No evaluation data found. Returning zero metrics.")
    return {"MRR": 0.0, "MRR@10": 0.0, "Recall@10": 0.0, "NDCG@10": 0.0, "MAP": 0.0}

def train_with_wandb(config: Optional[Dict] = None) -> Dict:
    """
    Train two-tower model with W&B logging and sweep support.
    
    Args:
        config: Configuration dictionary (from wandb.config or manual)
        
    Returns:
        Dictionary with training and evaluation history
    """
    
    # Initialize wandb run
    if config is None:
        # For sweeps, wandb.init() is called automatically by the agent
        # We just need to get the default config and let wandb.init() handle the rest
        config = get_default_config()
    
    # Initialize wandb run if not already initialized (for single runs)
    if not wandb.run:
        wandb.init(
            project="two-tower-msmarco",
            config=config,
            tags=["two-tower", "msmarco", "contrastive-learning"]
        )
    
    # Get config from wandb (this handles both sweep and manual configs)
    cfg = wandb.config
    
    # Setup evaluation module with configurable path
    setup_evaluation_module(cfg.get('evaluation_path', './evaluation'))
    
    print("üöÄ Two-Tower Training with Weights & Biases")
    print("=" * 70)
    print(f"üìä W&B Run: {wandb.run.name}")
    print(f"üîó W&B URL: {wandb.run.url}")
    
    # Device
    device = torch.device('cuda' if torch.cuda.is_available() else 
                         'mps' if torch.backends.mps.is_available() else 'cpu')
    print(f"üîß Using device: {device}")
    
    # Log system info
    wandb.log({
        "system/device": str(device),
        "system/cuda_available": torch.cuda.is_available(),
        "system/mps_available": torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False
    })
    
    # Load pre-trained embeddings
    print("üì¶ Loading pre-trained embeddings...")
    # Try multiple possible locations for embeddings
    possible_paths = [
        os.path.join(cfg.checkpoint_dir, "msmarco_word2vec.pt"),
        os.path.join("./checkpoints", "msmarco_word2vec.pt"),
        os.path.join(os.path.dirname(__file__), "checkpoints", "msmarco_word2vec.pt")
    ]
    
    embeddings_path = None
    for path in possible_paths:
        if os.path.exists(path):
            embeddings_path = path
            break
    
    if embeddings_path is None:
        error_msg = f"Pre-trained embeddings not found in any of these locations: {possible_paths}"
        print(f"‚ùå Error: {error_msg}")
        wandb.log({"error": error_msg})
        raise FileNotFoundError(error_msg)
    
    checkpoint = torch.load(embeddings_path, map_location='cpu')
    embedding_matrix = checkpoint["embedding_matrix"]
    word_to_index = checkpoint["word_to_index"]
    index_to_word = checkpoint["index_to_word"]
    
    print(f"‚úÖ Loaded embeddings: {embedding_matrix.shape}")
    wandb.log({
        "model/vocab_size": embedding_matrix.shape[0],
        "model/embedding_dim": embedding_matrix.shape[1]
    })
    
    # Create model with hyperparameters from config
    model = TwoTowerModel(
        embedding_matrix=embedding_matrix,
        word_to_index=word_to_index,
        hidden_dim=cfg.hidden_dim,
        num_layers=cfg.num_layers,
        dropout=cfg.dropout
    ).to(device)
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"üèóÔ∏è  Model created with {total_params:,} parameters ({trainable_params:,} trainable)")
    
    # Log model info
    wandb.log({
        "model/total_parameters": total_params,
        "model/trainable_parameters": trainable_params,
        "model/hidden_dim": cfg.hidden_dim,
        "model/num_layers": cfg.num_layers,
        "model/dropout": cfg.dropout,
        "loss/type": cfg.loss_type,
        "loss/temperature": cfg.temperature,
        "loss/margin": cfg.margin if cfg.loss_type in ["margin_contrastive", "triplet"] else None
    })
    
    # Watch model (log gradients and parameters)
    wandb.watch(model, log="all", log_freq=100)
    
    # Load dataset
    dataset = PreprocessedMSMarcoDataset(cfg.triplets_file)
    dataset_size = len(dataset)
    
    print(f"üìä Dataset size: {dataset_size:,} triplets")
    wandb.log({"data/dataset_size": dataset_size})
    
    # Create DataLoader
    if cfg.num_workers > 0:
        collator = TwoTowerCollator(model)
        dataloader = DataLoader(
            dataset,
            batch_size=cfg.batch_size,
            shuffle=True,
            num_workers=cfg.num_workers,
            collate_fn=collator,
            pin_memory=True if device.type == 'cuda' else False
        )
    else:
        from two_tower_model import collate_fn
        dataloader = DataLoader(
            dataset,
            batch_size=cfg.batch_size,
            shuffle=True,
            num_workers=0,
            collate_fn=lambda batch: collate_fn(batch, model)
        )
    
    # Loss and optimizer with hyperparameters
    if cfg.loss_type == "contrastive":
        criterion = ContrastiveLoss(temperature=cfg.temperature)
    elif cfg.loss_type == "margin_contrastive":
        criterion = MarginContrastiveLoss(margin=cfg.margin, temperature=cfg.temperature)
    elif cfg.loss_type == "triplet":
        criterion = TripletLoss(margin=cfg.margin, temperature=cfg.temperature)
    else:
        raise ValueError(f"Unknown loss type: {cfg.loss_type}")
    
    # Choose optimizer based on config
    if cfg.optimizer == "adamw":
        optimizer = torch.optim.AdamW(
            model.parameters(), 
            lr=cfg.learning_rate, 
            weight_decay=cfg.weight_decay,
            betas=(cfg.beta1, cfg.beta2)
        )
    elif cfg.optimizer == "adam":
        optimizer = torch.optim.Adam(
            model.parameters(), 
            lr=cfg.learning_rate, 
            weight_decay=cfg.weight_decay,
            betas=(cfg.beta1, cfg.beta2)
        )
    else:
        optimizer = torch.optim.SGD(
            model.parameters(), 
            lr=cfg.learning_rate, 
            weight_decay=cfg.weight_decay,
            momentum=0.9
        )
    
    # Choose scheduler based on config
    if cfg.scheduler == "cosine":
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=len(dataloader) * cfg.epochs
        )
    elif cfg.scheduler == "step":
        scheduler = torch.optim.lr_scheduler.StepLR(
            optimizer, step_size=cfg.epochs // 3, gamma=0.1
        )
    elif cfg.scheduler == "reduce_on_plateau":
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=2, verbose=True
        )
    else:
        scheduler = None
    
    print(f"üéØ Training configuration:")
    print(f"   Epochs: {cfg.epochs}")
    print(f"   Batch size: {cfg.batch_size}")
    print(f"   Learning rate: {cfg.learning_rate}")
    print(f"   Optimizer: {cfg.optimizer}")
    print(f"   Scheduler: {cfg.scheduler}")
    print(f"   Loss type: {cfg.loss_type}")
    print(f"   Temperature: {cfg.temperature}")
    if cfg.loss_type in ["margin_contrastive", "triplet"]:
        print(f"   Margin: {cfg.margin}")
    print(f"   Weight decay: {cfg.weight_decay}")
    
    # Training history
    training_history = {
        'training_stats': [],
        'evaluation_stats': [],
        'best_metrics': {},
        'best_epoch': 0,
        'config': dict(cfg)
    }
    
    best_mrr = 0.0
    epochs_without_improvement = 0
    
    print("=" * 70)
    print("üéØ Starting Training with W&B Logging")
    print("=" * 70)
    
    for epoch in range(cfg.epochs):
        print(f"\nüìö Epoch {epoch + 1}/{cfg.epochs}")
        
        # Training phase
        model.train()
        epoch_loss = 0
        epoch_accuracy = 0
        num_batches = 0
        
        for batch_idx, batch in enumerate(tqdm(dataloader, desc=f"Training Epoch {epoch+1}")):
            # Move to device
            query_ids = batch['query_ids'].to(device)
            pos_doc_ids = batch['pos_doc_ids'].to(device)
            neg_doc_ids = batch['neg_doc_ids'].to(device)
            
            # Forward pass
            optimizer.zero_grad()
            query_emb, pos_doc_emb, neg_doc_emb = model(query_ids, pos_doc_ids, neg_doc_ids)
            
            # Compute loss
            loss, accuracy = criterion(query_emb, pos_doc_emb, neg_doc_emb)
            
            # Backward pass
            loss.backward()
            
            # Gradient clipping
            if cfg.grad_clip > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg.grad_clip)
            
            optimizer.step()
            
            if scheduler and cfg.scheduler != "reduce_on_plateau":
                scheduler.step()
            
            # Track metrics
            epoch_loss += loss.item()
            epoch_accuracy += accuracy.item()
            num_batches += 1
            
            # Log to W&B every N steps
            if (batch_idx + 1) % cfg.log_freq == 0:
                step = epoch * len(dataloader) + batch_idx + 1
                avg_loss = epoch_loss / num_batches
                avg_acc = epoch_accuracy / num_batches
                lr = optimizer.param_groups[0]['lr']
                
                wandb.log({
                    "train/loss": loss.item(),
                    "train/accuracy": accuracy.item(),
                    "train/avg_loss": avg_loss,
                    "train/avg_accuracy": avg_acc,
                    "train/learning_rate": lr,
                    "train/epoch": epoch + 1,
                    "train/step": step
                })
                
                print(f"  Batch {batch_idx + 1:4d}/{len(dataloader)} | "
                      f"Loss: {avg_loss:.4f} | Acc: {avg_acc:.4f} | LR: {lr:.2e}")
        
        # Epoch training summary
        final_loss = epoch_loss / num_batches
        final_accuracy = epoch_accuracy / num_batches
        
        epoch_stats = {
            'epoch': epoch + 1,
            'train_loss': final_loss,
            'train_accuracy': final_accuracy,
            'learning_rate': optimizer.param_groups[0]['lr']
        }
        
        print(f"üìä Epoch {epoch + 1} Training Summary:")
        print(f"   Loss: {final_loss:.4f}")
        print(f"   Accuracy: {final_accuracy:.4f}")
        
        # Log epoch metrics to W&B
        wandb.log({
            "epoch/train_loss": final_loss,
            "epoch/train_accuracy": final_accuracy,
            "epoch/learning_rate": optimizer.param_groups[0]['lr'],
            "epoch/epoch": epoch + 1
        })
        
        # Evaluation phase
        if cfg.eval_every_epoch:
            print(f"\nüîç Evaluating after epoch {epoch + 1}...")
            
            try:
                eval_results = evaluate_trained_model_wrapper(
                    model=model,
                    device=device,
                    epoch=epoch + 1,
                    data_path="./data",  # Use current directory's data folder
                    max_queries=cfg.eval_max_queries
                )
                
                # Add evaluation results to epoch stats
                epoch_stats.update({
                    'eval_mrr': eval_results.get('MRR', 0),
                    'eval_mrr@10': eval_results.get('MRR@10', 0),
                    'eval_recall@10': eval_results.get('Recall@10', 0),
                    'eval_ndcg@10': eval_results.get('NDCG@10', 0),
                    'eval_map': eval_results.get('MAP', 0)
                })
                
                training_history['evaluation_stats'].append(eval_results)
                
                print(f"üìà Validation Results:")
                print(f"   MRR: {eval_results.get('MRR', 0):.4f}")
                print(f"   MRR@10: {eval_results.get('MRR@10', 0):.4f}")
                print(f"   Recall@10: {eval_results.get('Recall@10', 0):.4f}")
                print(f"   NDCG@10: {eval_results.get('NDCG@10', 0):.4f}")
                
                # Log evaluation metrics to W&B
                wandb.log({
                    "eval/MRR": eval_results.get('MRR', 0),
                    "eval/MRR@10": eval_results.get('MRR@10', 0),
                    "eval/Recall@10": eval_results.get('Recall@10', 0),
                    "eval/NDCG@10": eval_results.get('NDCG@10', 0),
                    "eval/MAP": eval_results.get('MAP', 0),
                    "epoch/epoch": epoch + 1
                })
                
                # Check if this is the best model
                current_mrr = eval_results.get('MRR', 0)
                if current_mrr > best_mrr:
                    best_mrr = current_mrr
                    training_history['best_metrics'] = eval_results
                    training_history['best_epoch'] = epoch + 1
                    epochs_without_improvement = 0
                    
                    print(f"üèÜ New best model! MRR improved to {best_mrr:.4f}")
                    
                    # Log best metrics
                    wandb.log({
                        "best/MRR": best_mrr,
                        "best/epoch": epoch + 1
                    })
                    
                    # Save best model
                    if cfg.save_best_only or epoch == cfg.epochs - 1:
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        model_filename = f"two_tower_best_{wandb.run.name}_{timestamp}.pt"
                        model_save_path = os.path.join(cfg.checkpoint_dir, model_filename)
                        
                        torch.save({
                            'model_state_dict': model.state_dict(),
                            'embedding_matrix': embedding_matrix,
                            'word_to_index': word_to_index,
                            'index_to_word': index_to_word,
                            'model_config': {
                                'hidden_dim': cfg.hidden_dim,
                                'num_layers': cfg.num_layers,
                                'dropout': cfg.dropout
                            },
                            'training_stats': training_history,
                            'epoch': epoch + 1,
                            'eval_results': eval_results,
                            'wandb_run_id': wandb.run.id
                        }, model_save_path)
                        
                        # Save model as W&B artifact
                        artifact = wandb.Artifact(
                            name=f"two_tower_model_{wandb.run.name}",
                            type="model",
                            description=f"Best two-tower model from run {wandb.run.name}"
                        )
                        artifact.add_file(model_save_path)
                        wandb.log_artifact(artifact)
                        
                        print(f"üíæ Best model saved to: {model_save_path}")
                        print(f"üîó Model artifact logged to W&B")
                else:
                    epochs_without_improvement += 1
                    print(f"üìâ No improvement. Best MRR: {best_mrr:.4f} (epoch {training_history['best_epoch']})")
                
                # Scheduler step for ReduceLROnPlateau
                if scheduler and cfg.scheduler == "reduce_on_plateau":
                    scheduler.step(current_mrr)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  Evaluation failed: {e}")
                wandb.log({"eval/error": str(e)})
                epoch_stats.update({
                    'eval_error': str(e)
                })
        
        training_history['training_stats'].append(epoch_stats)
        
        # Early stopping check
        if cfg.patience > 0 and epochs_without_improvement >= cfg.patience:
            print(f"\nüõë Early stopping triggered after {cfg.patience} epochs without improvement")
            wandb.log({"early_stop/epoch": epoch + 1, "early_stop/triggered": True})
            break
    
    print("=" * 70)
    print("‚úÖ Training with W&B completed!")
    
    if training_history['best_metrics']:
        print(f"üèÜ Best Results (Epoch {training_history['best_epoch']}):")
        best = training_history['best_metrics']
        print(f"   MRR: {best.get('MRR', 0):.4f}")
        print(f"   MRR@10: {best.get('MRR@10', 0):.4f}")
        print(f"   Recall@10: {best.get('Recall@10', 0):.4f}")
        print(f"   NDCG@10: {best.get('NDCG@10', 0):.4f}")
        
        # Log final summary
        wandb.summary.update({
            "final/best_MRR": best.get('MRR', 0),
            "final/best_epoch": training_history['best_epoch'],
            "final/total_epochs": epoch + 1,
            "final/early_stopped": epochs_without_improvement >= cfg.patience if cfg.patience > 0 else False
        })
    
    # Finish W&B run
    wandb.finish()
    
    return training_history

def get_default_config() -> Dict:
    """Get default configuration for training."""
    return {
        # Data
        "checkpoint_dir": "./checkpoints",
        "evaluation_path": "./evaluation",  # Path to evaluation directory
        
        # Model architecture
        "hidden_dim": 256,
        "num_layers": 2,
        "dropout": 0.1,
        
        # Training
        "epochs": 5,
        "batch_size": 32,
        "learning_rate": 1e-4,
        "optimizer": "adamw",  # adamw, adam, sgd
        "weight_decay": 1e-5,
        "beta1": 0.9,
        "beta2": 0.999,
        "grad_clip": 1.0,
        
        # Loss
        "loss_type": "contrastive",  # contrastive, margin_contrastive, triplet
        "temperature": 0.1,
        "margin": 0.2,  # Used for margin_contrastive and triplet losses
        
        # Scheduler
        "scheduler": "cosine",  # cosine, step, reduce_on_plateau, none
        
        # Evaluation
        "eval_every_epoch": True,
        "eval_max_queries": 1000,
        
        # Logging
        "log_freq": 200,
        
        # Saving
        "save_best_only": True,
        "patience": 3,
        
        # System
        "num_workers": 0
    }

def create_sweep_config() -> Dict:
    """Create W&B sweep configuration for hyperparameter tuning."""
    return {
        "method": "bayes",  # bayes, grid, random
        "metric": {
            "name": "eval/MRR",
            "goal": "maximize"
        },
        "parameters": {
            # Model architecture
            "hidden_dim": {
                "values": [128, 256, 512]
            },
            "num_layers": {
                "values": [1, 2, 3]
            },
            "dropout": {
                "distribution": "uniform",
                "min": 0.0,
                "max": 0.3
            },
            
            # Training
            "batch_size": {
                "values": [16, 32, 64]
            },
            "learning_rate": {
                "distribution": "log_uniform_values",
                "min": 1e-5,
                "max": 1e-3
            },
            "optimizer": {
                "values": ["adamw", "adam"]
            },
            "weight_decay": {
                "distribution": "log_uniform_values",
                "min": 1e-6,
                "max": 1e-3
            },
            
            # Loss Function
            "loss_type": {
                "values": ["contrastive", "margin_contrastive", "triplet"]
            },
            "temperature": {
                "distribution": "uniform",
                "min": 0.05,
                "max": 0.3
            },
            "margin": {
                "distribution": "uniform",
                "min": 0.1,
                "max": 0.5
            },
            
            # Scheduler
            "scheduler": {
                "values": ["cosine", "step", "reduce_on_plateau"]
            }
        },
        "early_terminate": {
            "type": "hyperband",
            "min_iter": 2
        }
    }

def main():
    """Main function with command line arguments."""
    parser = argparse.ArgumentParser(description="Train two-tower model with W&B")
    parser.add_argument("--triplets-file", 
                       required=True,
                       help="Path to pre-generated triplets file (.pkl)")
    parser.add_argument("--checkpoint-dir", 
                       default="./checkpoints",
                       help="Directory to save model checkpoints (default: ./checkpoints)")
    parser.add_argument("--evaluation-path", 
                       default="./evaluation",
                       help="Path to evaluation directory (default: ./evaluation)")
    parser.add_argument("--project", default="two-tower-msmarco",
                       help="W&B project name")
    parser.add_argument("--sweep", action="store_true",
                       help="Create and run a hyperparameter sweep")
    parser.add_argument("--sweep-count", type=int, default=20,
                       help="Number of sweep runs (default: 20)")
    parser.add_argument("--config", type=str,
                       help="Path to custom config JSON file")
    
    # Individual hyperparameters (override defaults)
    parser.add_argument("--epochs", type=int, help="Number of training epochs")
    parser.add_argument("--batch-size", type=int, help="Batch size")
    parser.add_argument("--learning-rate", type=float, help="Learning rate")
    parser.add_argument("--hidden-dim", type=int, help="Hidden dimension")
    parser.add_argument("--num-layers", type=int, help="Number of layers")
    parser.add_argument("--dropout", type=float, help="Dropout rate")
    parser.add_argument("--temperature", type=float, help="Contrastive loss temperature")
    parser.add_argument("--margin", type=float, help="Margin for margin-based losses")
    parser.add_argument("--loss-type", choices=["contrastive", "margin_contrastive", "triplet"],
                       help="Loss function type")
    
    args = parser.parse_args()
    
    # Validate triplets file
    if not os.path.exists(args.triplets_file):
        print(f"‚ùå Error: Triplets file not found: {args.triplets_file}")
        return
    
    if args.sweep:
        # Create and run hyperparameter sweep
        print("üîç Creating hyperparameter sweep...")
        
        sweep_config = create_sweep_config()
        
        # Override sweep config with fixed values
        fixed_params = {
            "triplets_file": args.triplets_file,
            "checkpoint_dir": args.checkpoint_dir,
            "evaluation_path": args.evaluation_path,
            "eval_every_epoch": True,
            "eval_max_queries": 1000,
            "save_best_only": True,
            "patience": 3,
            "num_workers": 0,
            "log_freq": 200,
            "epochs": 5  # Keep epochs reasonable for sweeps
        }
        
        for key, value in fixed_params.items():
            sweep_config["parameters"][key] = {"value": value}
        
        # Initialize sweep
        sweep_id = wandb.sweep(sweep_config, project=args.project)
        print(f"üöÄ Created sweep: {sweep_id}")
        print(f"üîó Sweep URL: https://wandb.ai/{wandb.api.default_entity}/{args.project}/sweeps/{sweep_id}")
        
        # Run sweep
        wandb.agent(sweep_id, train_with_wandb, count=args.sweep_count)
        
    else:
        # Single training run
        config = get_default_config()
        
        # Set mandatory and configurable parameters
        config["triplets_file"] = args.triplets_file
        config["checkpoint_dir"] = args.checkpoint_dir
        config["evaluation_path"] = args.evaluation_path
        
        # Override with custom config file
        if args.config and os.path.exists(args.config):
            with open(args.config, 'r') as f:
                custom_config = json.load(f)
            config.update(custom_config)
            # Ensure command line arguments take precedence
            config["triplets_file"] = args.triplets_file
            config["checkpoint_dir"] = args.checkpoint_dir
            config["evaluation_path"] = args.evaluation_path
        
        if args.epochs is not None:
            config["epochs"] = args.epochs
        if args.batch_size is not None:
            config["batch_size"] = args.batch_size
        if args.learning_rate is not None:
            config["learning_rate"] = args.learning_rate
        if args.hidden_dim is not None:
            config["hidden_dim"] = args.hidden_dim
        if args.num_layers is not None:
            config["num_layers"] = args.num_layers
        if args.dropout is not None:
            config["dropout"] = args.dropout
        if args.temperature is not None:
            config["temperature"] = args.temperature
        if args.margin is not None:
            config["margin"] = args.margin
        if args.loss_type is not None:
            config["loss_type"] = args.loss_type
        
        # Initialize W&B
        wandb.init(
            project=args.project,
            config=config,
            tags=["two-tower", "msmarco", "single-run"]
        )
        
        # Train model
        history = train_with_wandb(config)
        
        print(f"\nüéâ Training completed successfully!")
        if history['best_metrics']:
            print(f"   Best MRR: {history['best_metrics'].get('MRR', 0):.4f} (Epoch {history['best_epoch']})")

if __name__ == "__main__":
    main() 